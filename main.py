import aiohttp
import os
import asyncio
import datetime
from typing import Optional, Dict, Any, List
from astrbot.api.event import filter, AstrMessageEvent
from astrbot.api.star import Context, Star, register
from astrbot.api.message_components import Image, Plain, Video, File
from astrbot.api import logger
from astrbot.core.message.message_event_result import MessageChain

# æ–‡ä»¶ç±»å‹å¯¹åº”çš„ Emoji æ˜ å°„
EMOJI_MAP = {
    "IMAGE": "ğŸ–¼ï¸",
    "VIDEO": "ğŸ“¹",
    "PDF": "ğŸ“„",
    "ZIP": "ğŸ“¦",
    "BOOK": "ğŸ“š",
    "TEXT": "ğŸ“",
    "DEFAULT": "ğŸ“"
}

@register("astrbot_plugin_meta_collect", "yunus", "å…ƒé‡‡é›†å¹³å°æœç´¢æ’ä»¶", "1.0.0")
class MelonSearchPlugin(Star):
    def __init__(self, context: Context, config: dict = None):
        super().__init__(context)
        self.config = config or {}
        self.base_url = self.config.get("base_url", "http://localhost:8080")
        self._session: Optional[aiohttp.ClientSession] = None

        # å®šæ—¶æ¨é€é…ç½®
        self.push_enabled = self.config.get("push_enabled", False)
        self.push_times = self.config.get("push_times", "08:00,12:00,17:00")
        self.push_check_hours = self.config.get("push_check_hours", 12)
        self.push_target_groups = self.config.get("push_target_groups", [])

        # å®šæ—¶ä»»åŠ¡åˆ—è¡¨
        self._push_tasks = []

    async def initialize(self):
        """åˆå§‹åŒ–æ—¶åˆ›å»ºæŒä¹…åŒ–çš„ HTTP ä¼šè¯å’Œå¯åŠ¨å®šæ—¶ä»»åŠ¡"""
        self._session = aiohttp.ClientSession()

        # å¯åŠ¨å®šæ—¶æ¨é€ä»»åŠ¡
        if self.push_enabled and self.push_target_groups:
            for push_time in self._parse_push_times():
                task = asyncio.create_task(self.push_task(push_time))
                self._push_tasks.append(task)
            logger.info(f"[ç“œæ¨é€] å·²å¯åŠ¨ {len(self._push_tasks)} ä¸ªå®šæ—¶æ¨é€ä»»åŠ¡")
        else:
            logger.info("[ç“œæ¨é€] å®šæ—¶æ¨é€åŠŸèƒ½æœªå¯ç”¨æˆ–æœªé…ç½®ç›®æ ‡ç¾¤ç»„")

    async def terminate(self):
        """ç»ˆæ­¢æ—¶å…³é—­ä¼šè¯å’Œå–æ¶ˆå®šæ—¶ä»»åŠ¡"""
        # å–æ¶ˆæ‰€æœ‰å®šæ—¶ä»»åŠ¡
        for task in self._push_tasks:
            task.cancel()

        # å…³é—­ä¼šè¯
        if self._session:
            await self._session.close()

        logger.info("[ç“œæ¨é€] å·²åœæ­¢æ‰€æœ‰å®šæ—¶ä»»åŠ¡å’Œä¼šè¯")

    def _parse_push_times(self) -> List[str]:
        """è§£ææ¨é€æ—¶é—´é…ç½®ï¼Œè¿”å›æ—¶é—´åˆ—è¡¨"""
        times = self.push_times.split(",")
        return [t.strip() for t in times if t.strip()]

    # ==========================================================
    # å·¥å…·æ–¹æ³•
    # ==========================================================

    async def _fetch_json(self, url: str, params: Optional[Dict] = None) -> Optional[Any]:
        """ç»Ÿä¸€çš„ HTTP GET è¯·æ±‚æ–¹æ³•ï¼Œè¿”å› JSON æ•°æ®"""
        try:
            async with self._session.get(url, params=params) as resp:
                if resp.status != 200:
                    logger.warning(f"HTTP è¯·æ±‚å¤±è´¥: {url}, çŠ¶æ€ç : {resp.status}")
                    return None
                return await resp.json()
        except Exception as e:
            logger.error(f"HTTP è¯·æ±‚å¼‚å¸¸: {url}, é”™è¯¯: {e}")
            return None

    def _extract_first_item(self, data: Any) -> Optional[Dict]:
        """ä»å“åº”æ•°æ®ä¸­æå–ç¬¬ä¸€ä¸ªæœ‰æ•ˆé¡¹"""
        if isinstance(data, list) and data:
            return data[0]
        elif isinstance(data, dict):
            return data
        return None

    async def _fetch_oss_url(self, oss_id: str) -> Optional[tuple[str, str]]:
        """è·å– OSS æ–‡ä»¶çš„çœŸå® URL å’ŒåŸå§‹æ–‡ä»¶å

        Returns:
            tuple[url, original_name] æˆ– None
        """
        url = f"{self.base_url}/resource/oss/web/listByIds/{oss_id}"
        oss_json = await self._fetch_json(url)

        if not oss_json or oss_json.get("code") != 200:
            return None

        oss_data = oss_json.get("data", [])
        if not oss_data:
            return None

        real_url = oss_data[0].get("url")
        original_name = oss_data[0].get("originalName", "æœªå‘½åæ–‡ä»¶")

        return (real_url, original_name) if real_url else None

    async def _get_all_group_files(self, group_id: int, bot) -> List[Dict]:
        """
        è·å–ç¾¤æ–‡æ¡£ä¸­çš„æ‰€æœ‰æ–‡ä»¶åˆ—è¡¨ï¼ˆé€’å½’è·å–æ‰€æœ‰æ–‡ä»¶å¤¹ï¼‰
        å…¼å®¹ç°æœ‰çš„ç¾¤æ–‡ä»¶è·å–å®ç°

        Returns:
            åŒ…å«æ–‡ä»¶ä¿¡æ¯çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º dictï¼Œè‡³å°‘åŒ…å« 'file_name' å’Œ 'file_id'
        """
        try:
            from .src.file_ops import get_all_files_recursive_core
            all_files = await get_all_files_recursive_core(group_id, bot)
            logger.info(f"ä»ç¾¤ {group_id} è·å–åˆ° {len(all_files)} ä¸ªç¾¤æ–‡æ¡£æ–‡ä»¶")
            return all_files
        except Exception as e:
            logger.warning(f"è·å–ç¾¤æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {e}")
            return []

    def _find_file_in_group(self, code: str, group_files: List[Dict]) -> Optional[Dict]:
        """
        åœ¨ç¾¤æ–‡æ¡£åˆ—è¡¨ä¸­æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
        æ–‡ä»¶åè§„åˆ™ï¼šæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ä¸ code å®Œå…¨ä¸€è‡´

        Args:
            code: è¦æŸ¥æ‰¾çš„ code
            group_files: ç¾¤æ–‡æ¡£æ–‡ä»¶åˆ—è¡¨

        Returns:
            åŒ¹é…çš„æ–‡ä»¶ä¿¡æ¯ dict æˆ– None
        """
        if not group_files:
            return None

        for file_info in group_files:
            file_name = file_info.get('file_name', '')
            # å»é™¤æ‰©å±•å
            base_name, _ = os.path.splitext(file_name)

            # æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ä¸ code å®Œå…¨åŒ¹é…
            if base_name == code:
                logger.info(f"åœ¨ç¾¤æ–‡æ¡£ä¸­æ‰¾åˆ°åŒ¹é…æ–‡ä»¶: {file_name} (code: {code})")
                return file_info

        return None

    def _format_search_result(self, item: Dict) -> str:
        """æ ¼å¼åŒ–å•æ¡æœç´¢ç»“æœ"""
        cid = item.get("code") or item.get("id")
        title = item.get("title", "æ— æ ‡é¢˜")
        file_type = item.get("fileType", "DEFAULT")
        emoji = EMOJI_MAP.get(file_type, EMOJI_MAP["DEFAULT"])
        return f" {emoji}ã€{cid}ã€‘{title}"

    def _format_file_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if size_bytes < 1024:
            return f"{size_bytes} B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.2f} KB"
        elif size_bytes < 1024 * 1024 * 1024:
            return f"{size_bytes / (1024 * 1024):.2f} MB"
        else:
            return f"{size_bytes / (1024 * 1024 * 1024):.2f} GB"

    # ==========================================================
    # æŒ‡ä»¤ï¼š/æœç“œ [å…³é”®è¯]
    # ==========================================================

    @filter.command("æœç“œ")
    async def search_melon(self, event: AstrMessageEvent):
        """æœç´¢èµ„æºï¼š/æœç“œ <å…³é”®è¯>"""
        # è§£æå…³é”®è¯
        parts = event.message_str.split(maxsplit=1)
        if len(parts) < 2 or not parts[1].strip():
            yield event.plain_result("âŒ è¯·è¾“å…¥æœç´¢å…³é”®è¯ï¼Œä¾‹å¦‚ï¼š/æœç“œ demo")
            return

        keyword = parts[1].strip()

        # è¯·æ±‚æœç´¢æ¥å£
        url = f"{self.base_url}/media/mediaData/web/list"
        params = {"contentText": keyword, "status": "enable"}

        data = await self._fetch_json(url, params)

        if data is None:
            yield event.plain_result(f"âŒ æœç´¢æ¥å£è¯·æ±‚å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•")
            return

        if not data:
            yield event.plain_result(f"ğŸ” æœç´¢ã€{keyword}ã€‘ï¼ŒæœªæŸ¥åˆ°ç›¸å…³ä¿¡æ¯")
            return

        # æ„å»ºç»“æœæ¶ˆæ¯
        count = len(data)
        msg_lines = [f"ğŸ” æœç´¢ã€{keyword}ã€‘ï¼Œå…±æŸ¥åˆ° {count} æ¡ä¿¡æ¯ï¼š\n"]
        msg_lines.extend(self._format_search_result(item) for item in data)
        msg_lines.append("\nğŸ’¡ è¾“å…¥ /cid [CODE] è·å–è¯¦æƒ…")
        msg_lines.append("ğŸ”‘ å¦‚éœ€è§£å‹å¯†ç è¯·æŸ¥çœ‹å…¬å‘Š")

        yield event.plain_result("\n".join(msg_lines))

    # ==========================================================
    # æŒ‡ä»¤ï¼š/cid [CODE]
    # ==========================================================

    @filter.command("cid")
    async def query_detail(self, event: AstrMessageEvent):
        """è·å–èµ„æºè¯¦æƒ…ï¼š/cid <CODE>"""
        # è§£æ CODE å‚æ•°
        parts = event.message_str.split(maxsplit=1)
        if len(parts) < 2 or not parts[1].strip():
            yield event.plain_result("âŒ è¯·è¾“å…¥ Codeï¼Œä¾‹å¦‚ï¼š/cid 2001")
            return

        cid_arg = parts[1].strip()
        yield event.plain_result(f"â³ æ­£åœ¨æŸ¥è¯¢ {cid_arg}ï¼Œè¯·ç¨ç­‰...")

        # 1. å°è¯•ä»ç¾¤æ–‡æ¡£è·å–æ–‡ä»¶
        group_id_str = event.get_group_id()
        group_file = None

        if group_id_str and event.bot:
            try:
                group_id = int(group_id_str)
                logger.info(f"æ­£åœ¨æ£€æŸ¥ç¾¤ {group_id} çš„æ–‡æ¡£...")
                group_files = await self._get_all_group_files(group_id, event.bot)
                group_file = self._find_file_in_group(cid_arg, group_files)

                if group_file:
                    logger.info(f"âœ… åœ¨ç¾¤æ–‡æ¡£ä¸­æ‰¾åˆ°æ–‡ä»¶ï¼Œè·³è¿‡ç½‘ç»œè¯·æ±‚")
                    # ç›´æ¥è¿”å›ç¾¤æ–‡æ¡£æ–‡ä»¶
                    chain = await self._build_group_file_chain(group_file, cid_arg)
                    yield event.chain_result(chain)
                    return
            except Exception as e:
                logger.warning(f"æ£€æŸ¥ç¾¤æ–‡æ¡£æ—¶å‡ºé”™: {e}ï¼Œç»§ç»­ä½¿ç”¨ç½‘ç»œæŸ¥è¯¢")

        # 2. ç¾¤æ–‡æ¡£ä¸­æœªæ‰¾åˆ°ï¼ŒæŸ¥è¯¢è¯¦æƒ…æ¥å£
        query_url = f"{self.base_url}/media/mediaData/web/query"
        raw_data = await self._fetch_json(query_url, params={"code": cid_arg})

        if raw_data is None:
            yield event.plain_result("âŒ è¯¦æƒ…æ¥å£è¯·æ±‚å¤±è´¥")
            return

        data = self._extract_first_item(raw_data)
        if not data:
            yield event.plain_result(f"âŒ æœªæ‰¾åˆ° Code ä¸º {cid_arg} çš„èµ„æº")
            return

        # 3. æ„å»ºæ¶ˆæ¯é“¾ï¼ˆç½‘ç»œæ–‡ä»¶ï¼‰
        chain = await self._build_detail_chain(data, cid_arg)
        yield event.chain_result(chain)

    async def _build_detail_chain(self, data: Dict, cid_arg: str) -> List:
        """æ„å»ºè¯¦æƒ…æ¶ˆæ¯é“¾"""
        chain = []

        # åŸºç¡€ä¿¡æ¯
        title = data.get("title", "æ— æ ‡é¢˜")
        cover_url = data.get("coverUrl", "")
        file_type = data.get("fileType", "DEFAULT")
        netdisk_type = data.get("netdiskType", "æœªçŸ¥ç½‘ç›˜")
        netdisk_url = data.get("netdiskUrl", "")

        # æ·»åŠ æ ‡é¢˜
        emoji = EMOJI_MAP.get(file_type, EMOJI_MAP["DEFAULT"])
        chain.append(Plain(f"{emoji} {title}\n"))

        # æ·»åŠ å°é¢
        if cover_url:
            chain.append(Image.fromURL(cover_url))

        # æ ¹æ®æ–‡ä»¶ç±»å‹æ·»åŠ å†…å®¹
        if file_type == "IMAGE":
            await self._add_images(chain, data)
        elif file_type == "VIDEO":
            await self._add_videos(chain, data)
        elif file_type in ["ZIP", "PDF"]:
            await self._add_files(chain, data, cid_arg)
        else:
            chain.append(Plain("\nâš ï¸ æš‚ä¸æ”¯æŒè¯¥æ–‡ä»¶ç±»å‹ï¼Œè¯·è”ç³»ç®¡ç†å‘˜"))

        # æ·»åŠ ç½‘ç›˜ä¿¡æ¯
        if netdisk_url:
            chain.append(Plain(f"\nğŸ“Œ è¯¦æƒ…ï¼šã€{netdisk_type}ã€‘\nğŸ”— {netdisk_url}"))

        return chain

    async def _build_group_file_chain(self, group_file: Dict, code: str) -> List:
        """
        æ„å»ºç¾¤æ–‡æ¡£æ–‡ä»¶çš„æ¶ˆæ¯é“¾

        Args:
            group_file: ç¾¤æ–‡æ¡£æ–‡ä»¶ä¿¡æ¯
            code: æ–‡ä»¶ code
        """
        chain = []

        file_name = group_file.get('file_name', 'æœªçŸ¥æ–‡ä»¶')
        file_id = group_file.get('file_id', '')
        file_size = group_file.get('size', 0)
        parent_folder = group_file.get('parent_folder_name', 'æ ¹ç›®å½•')

        # æ ¹æ®æ‰©å±•ååˆ¤æ–­æ–‡ä»¶ç±»å‹
        _, ext = os.path.splitext(file_name)
        ext_upper = ext.upper().lstrip('.')

        # æ˜ å°„æ‰©å±•ååˆ° emoji
        emoji = EMOJI_MAP.get(ext_upper, EMOJI_MAP["DEFAULT"])

        # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
        size_str = self._format_file_size(file_size)

        # æ·»åŠ æ ‡é¢˜å’Œä¿¡æ¯
        text = (
            f"{emoji} ç¾¤æ–‡ä»¶å†…å·²å­˜åœ¨: {file_name}\n"
            f"ğŸ“‚ æ‰€åœ¨æ–‡ä»¶å¤¹ï¼š{parent_folder}\n"
            f"ğŸ“¦ æ–‡ä»¶å¤§å°ï¼š{size_str}\n"
            f"ğŸ”‘ å¦‚éœ€è§£å‹å¯†ç è¯·æŸ¥çœ‹å…¬å‘Š"
        )

        chain.append(Plain(text))

        logger.info(f"ä»ç¾¤æ–‡æ¡£è¿”å›æ–‡ä»¶: {file_name}, å¤§å°: {size_str}")

        return chain

    async def _add_images(self, chain: List, data: Dict):
        """æ·»åŠ å›¾ç‰‡åˆ°æ¶ˆæ¯é“¾"""
        images_str = data.get("imagesUrl", "")
        if images_str:
            img_urls = [url.strip() for url in images_str.split(",") if url.strip()]
            for url in img_urls:
                chain.append(Image.fromURL(url))

    async def _add_videos(self, chain: List, data: Dict):
        """æ·»åŠ è§†é¢‘åˆ°æ¶ˆæ¯é“¾"""
        video_urls = data.get("videoUrls", "")
        if not video_urls:
            chain.append(Plain("\nâš ï¸ æœªæ‰¾åˆ°è§†é¢‘èµ„æº"))
            return

        oss_ids = [i.strip() for i in video_urls.split(",") if i.strip()]
        for oss_id in oss_ids:
            result = await self._fetch_oss_url(oss_id)
            if result:
                real_url, _ = result
                chain.append(Video.fromURL(real_url))

    async def _add_files(self, chain: List, data: Dict, fallback_name: str):
        """æ·»åŠ æ–‡ä»¶åˆ°æ¶ˆæ¯é“¾"""
        file_urls = data.get("fileUrls", "")
        if not file_urls:
            chain.append(Plain("\nâš ï¸ æœªæ‰¾åˆ°æ–‡ä»¶èµ„æº"))
            return

        oss_ids = [i.strip() for i in file_urls.split(",") if i.strip()]
        for oss_id in oss_ids:
            result = await self._fetch_oss_url(oss_id)
            if result:
                real_url, original_name = result
                chain.append(File(url=real_url, name=original_name or fallback_name))

    @filter.command("æ–°ç“œ")
    async def check_updates(self, event: AstrMessageEvent, hours: int = None):
        """
        æ£€æŸ¥æ–°ç“œæ›´æ–°

        Args:
            hours: æ£€æŸ¥æœ€è¿‘å¤šå°‘å°æ—¶ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®å€¼
        """
        try:
            check_hours = hours or self.push_check_hours
            logger.info(f"[ç“œæ¨é€] æ‰‹åŠ¨æ£€æŸ¥æœ€è¿‘ {check_hours} å°æ—¶çš„æ›´æ–°")

            melons = await self.fetch_recent_updates(check_hours)
            message_text = self.format_push_message(melons, check_hours)

            yield event.plain_result(message_text)
        except Exception as e:
            logger.error(f"[ç“œæ¨é€] æ£€æŸ¥æ›´æ–°æ—¶å‡ºé”™: {e}")
            yield event.plain_result(f"âŒ æ£€æŸ¥å¤±è´¥: {str(e)}")
        finally:
            event.stop_event()

    # ==========================================================
    # å®šæ—¶æ¨é€åŠŸèƒ½
    # ==========================================================

    async def fetch_recent_updates(self, hours: int = 12) -> List[Dict]:
        """
        è·å–æœ€è¿‘Nå°æ—¶æ›´æ–°çš„ç“œ

        Args:
            hours: æŸ¥è¯¢æœ€è¿‘å¤šå°‘å°æ—¶çš„æ›´æ–°

        Returns:
            ç“œåˆ—è¡¨
        """
        try:
            # è®¡ç®—æ—¶é—´èŒƒå›´
            now = datetime.datetime.now()
            start_time = now - datetime.timedelta(hours=12)

            params = {
                "updateTimeStart": start_time.strftime("%Y-%m-%d %H:%M:%S"),
                "updateTimeEnd": now.strftime("%Y-%m-%d %H:%M:%S"),
                "status": "enable"
            }

            url = f"{self.base_url}/media/mediaData/web/list"
            # params = {
            #     "updateTime": update_time,
            #     "status": "enable"
            # }

            logger.info(f"[ç“œæ¨é€] æŸ¥è¯¢æœ€è¿‘ {hours} å°æ—¶çš„æ›´æ–°ï¼Œæ—¶é—´æˆ³: {start_time}")

            data = await self._fetch_json(url, params)

            if data is None:
                logger.error("[ç“œæ¨é€] æ¥å£è¯·æ±‚å¤±è´¥")
                return []

            if not data:
                logger.info(f"[ç“œæ¨é€] æœ€è¿‘ {hours} å°æ—¶æ²¡æœ‰æ–°ç“œ")
                return []

            logger.info(f"[ç“œæ¨é€] æ‰¾åˆ° {len(data)} ä¸ªæ–°ç“œ")
            return data

        except Exception as e:
            logger.error(f"[ç“œæ¨é€] è·å–æ–°ç“œæ—¶å‡ºé”™: {e}")
            return []

    def format_push_message(self, melons: List[Dict], hours: int) -> str:
        """
        æ ¼å¼åŒ–æ¨é€æ¶ˆæ¯

        Args:
            melons: ç“œåˆ—è¡¨
            hours: æ—¶é—´èŒƒå›´ï¼ˆå°æ—¶ï¼‰

        Returns:
            æ ¼å¼åŒ–åçš„æ¶ˆæ¯æ–‡æœ¬
        """
        if not melons:
            return f"ğŸ“¢ æœ€è¿‘ {hours} å°æ—¶æ²¡æœ‰æ–°ç“œæ›´æ–°"

        msg_lines = [
            f"ğŸ‰ æ–°ç“œé€Ÿé€’ ğŸ‰",
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
            f"ğŸ“Š æœ€è¿‘ {hours} å°æ—¶æ›´æ–°äº† {len(melons)} ä¸ªç“œï¼š\n"
        ]

        for i, item in enumerate(melons, 1):
            cid = item.get("code") or item.get("id")
            title = item.get("title", "æ— æ ‡é¢˜")
            file_type = item.get("fileType", "DEFAULT")
            emoji = EMOJI_MAP.get(file_type, EMOJI_MAP["DEFAULT"])

            # è·å–æ›´æ–°æ—¶é—´
            update_time = item.get("updateTime")
            time_str = ""
            if update_time:
                try:
                    dt = datetime.datetime.fromtimestamp(update_time / 1000)
                    time_str = dt.strftime("%m-%d %H:%M")
                except:
                    pass

            msg_lines.append(f"{i}. {emoji} [{cid}] {title}")
            if time_str:
                msg_lines.append(f"   â° {time_str}")

        msg_lines.append("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        msg_lines.append("ğŸ’¡ è¾“å…¥ /cid [CODE] æŸ¥çœ‹è¯¦æƒ…")
        msg_lines.append("ğŸ”‘ å¦‚éœ€è§£å‹å¯†ç è¯·æŸ¥çœ‹å…¬å‘Š")

        return "\n".join(msg_lines)

    async def send_push_to_groups(self):
        """å‘ç›®æ ‡ç¾¤ç»„æ¨é€æ–°ç“œ"""
        try:
            # è·å–æœ€è¿‘çš„ç“œ
            melons = await self.fetch_recent_updates(self.push_check_hours)

            if not self.push_target_groups:
                logger.info("[ç“œæ¨é€] æœªé…ç½®ç›®æ ‡ç¾¤ç»„")
                return

            # æ ¼å¼åŒ–æ¶ˆæ¯
            message_text = self.format_push_message(melons, self.push_check_hours)

            logger.info(f"[ç“œæ¨é€] å‡†å¤‡å‘ {len(self.push_target_groups)} ä¸ªç¾¤ç»„æ¨é€")

            for group_id in self.push_target_groups:
                try:
                    message_chain = MessageChain()
                    message_chain.chain = [Plain(message_text)]

                    await self.context.send_message(str(group_id), message_chain)
                    logger.info(f"[ç“œæ¨é€] å·²å‘ç¾¤ {group_id} æ¨é€æ–°ç“œé€šçŸ¥")

                    await asyncio.sleep(1)  # é¿å…å‘é€è¿‡å¿«
                except Exception as e:
                    logger.error(f"[ç“œæ¨é€] å‘ç¾¤ç»„ {group_id} æ¨é€æ¶ˆæ¯æ—¶å‡ºé”™: {e}")

        except Exception as e:
            logger.error(f"[ç“œæ¨é€] æ¨é€æ–°ç“œæ—¶å‡ºé”™: {e}")

    def calculate_sleep_time(self, target_time: str) -> float:
        """
        è®¡ç®—åˆ°ä¸‹ä¸€æ¬¡æ¨é€æ—¶é—´çš„ç§’æ•°

        Args:
            target_time: ç›®æ ‡æ—¶é—´ï¼Œæ ¼å¼å¦‚ "08:00"

        Returns:
            éœ€è¦ç­‰å¾…çš„ç§’æ•°
        """
        now = datetime.datetime.now()
        hour, minute = map(int, target_time.split(":"))

        target = now.replace(hour=hour, minute=minute, second=0, microsecond=0)
        if target <= now:
            target += datetime.timedelta(days=1)

        seconds = (target - now).total_seconds()
        return seconds

    async def push_task(self, push_time: str):
        """
        å®šæ—¶æ¨é€ä»»åŠ¡

        Args:
            push_time: æ¨é€æ—¶é—´ï¼Œæ ¼å¼å¦‚ "08:00"
        """
        logger.info(f"[ç“œæ¨é€] å¯åŠ¨å®šæ—¶ä»»åŠ¡ï¼Œæ¨é€æ—¶é—´: {push_time}")

        while True:
            try:
                # è®¡ç®—åˆ°ä¸‹æ¬¡æ¨é€çš„æ—¶é—´
                sleep_time = self.calculate_sleep_time(push_time)
                logger.info(f"[ç“œæ¨é€-{push_time}] ä¸‹æ¬¡æ¨é€å°†åœ¨ {sleep_time / 3600:.2f} å°æ—¶å")

                # ç­‰å¾…åˆ°è®¾å®šæ—¶é—´
                await asyncio.sleep(sleep_time)

                # æ¨é€æ–°ç“œ
                logger.info(f"[ç“œæ¨é€-{push_time}] å¼€å§‹æ‰§è¡Œæ¨é€")
                await self.send_push_to_groups()

                # ç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œé¿å…é‡å¤æ¨é€
                await asyncio.sleep(60)
            except asyncio.CancelledError:
                logger.info(f"[ç“œæ¨é€-{push_time}] å®šæ—¶ä»»åŠ¡å·²å–æ¶ˆ")
                break
            except Exception as e:
                logger.error(f"[ç“œæ¨é€-{push_time}] å®šæ—¶ä»»åŠ¡å‡ºé”™: {e}")
                await asyncio.sleep(300)

    @filter.command("gua_push_now")
    async def manual_push(self, event: AstrMessageEvent):
        """æ‰‹åŠ¨è§¦å‘æ¨é€"""
        try:
            logger.info("[ç“œæ¨é€] æ‰‹åŠ¨è§¦å‘æ¨é€")
            await self.send_push_to_groups()

            yield event.plain_result(
                f"âœ… å·²æˆåŠŸå‘ {len(self.push_target_groups)} ä¸ªç¾¤ç»„æ¨é€æ–°ç“œé€šçŸ¥"
            )
        except Exception as e:
            logger.error(f"[ç“œæ¨é€] æ‰‹åŠ¨æ¨é€æ—¶å‡ºé”™: {e}")
            yield event.plain_result(f"âŒ æ¨é€å¤±è´¥: {str(e)}")
        finally:
            event.stop_event()

    @filter.command("gua_push_status")
    async def check_push_status(self, event: AstrMessageEvent):
        """æŸ¥çœ‹æ¨é€çŠ¶æ€"""
        status_msg = [
            "ğŸ‰ ç“œæ¨é€æ’ä»¶çŠ¶æ€",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
        ]

        if self.push_enabled:
            status_msg.extend([
                f"âœ… çŠ¶æ€: å·²å¯ç”¨",
                f"ğŸ“ ç›®æ ‡ç¾¤ç»„: {', '.join(map(str, self.push_target_groups))}",
                f"â° æ¨é€æ—¶é—´: {self.push_times}",
                f"ğŸ• æ£€æŸ¥æ—¶é•¿: æœ€è¿‘{self.push_check_hours}å°æ—¶",
                f"ğŸ“Š ä»»åŠ¡æ•°é‡: {len(self._push_tasks)}ä¸ª"
            ])

            # è®¡ç®—æ¯ä¸ªä»»åŠ¡çš„ä¸‹æ¬¡æ¨é€æ—¶é—´
            status_msg.append("\nâ° ä¸‹æ¬¡æ¨é€æ—¶é—´:")
            for push_time in self._parse_push_times():
                sleep_time = self.calculate_sleep_time(push_time)
                hours = int(sleep_time / 3600)
                minutes = int((sleep_time % 3600) / 60)
                status_msg.append(f"  â€¢ {push_time} - è¿˜æœ‰{hours}å°æ—¶{minutes}åˆ†é’Ÿ")
        else:
            status_msg.append("âŒ çŠ¶æ€: æœªå¯ç”¨")

        yield event.plain_result("\n".join(status_msg))